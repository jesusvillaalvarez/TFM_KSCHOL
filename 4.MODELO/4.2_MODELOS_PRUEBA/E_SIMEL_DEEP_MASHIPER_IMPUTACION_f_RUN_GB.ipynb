{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "# Preprocesado y modelado\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import missingno\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Period</th>\n",
       "      <th>PREVISION</th>\n",
       "      <th>E_SIMEL</th>\n",
       "      <th>DESVIO</th>\n",
       "      <th>f_PREV_HIGH</th>\n",
       "      <th>f_PREV_LOW</th>\n",
       "      <th>f_RUN</th>\n",
       "      <th>Dia_Semana</th>\n",
       "      <th>Es_fin_semana</th>\n",
       "      <th>Año</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Día</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Fecha  Period  PREVISION  E_SIMEL  DESVIO  f_PREV_HIGH  \\\n",
       "0           0  2021-01-01       1        0.0      0.0     0.0            0   \n",
       "1           1  2021-01-01       2        0.0      0.0     0.0            0   \n",
       "2           2  2021-01-01       3        0.0      0.0     0.0            0   \n",
       "3           3  2021-01-01       4        0.0      0.0     0.0            0   \n",
       "4           4  2021-01-01       5        0.0      0.0     0.0            0   \n",
       "\n",
       "   f_PREV_LOW  f_RUN  Dia_Semana  Es_fin_semana   Año  Mes  Día  \n",
       "0           0      0           4          False  2021    1    1  \n",
       "1           0      0           4          False  2021    1    1  \n",
       "2           0      0           4          False  2021    1    1  \n",
       "3           0      0           4          False  2021    1    1  \n",
       "4           0      0           4          False  2021    1    1  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargamos el archivo csv con los datos\n",
    "\n",
    "df_central = pd.read_csv(\"C:/Users/Windows 10/Desktop/MASTER DATASCIENCE/TFM/df_central_2_1.csv\")\n",
    "\n",
    "df_central.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las columnas innecesarias\n",
    "\n",
    "df_central = df_central.drop(columns=['Unnamed: 0', 'DESVIO', 'f_PREV_HIGH', 'f_PREV_LOW'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos la columna 'Fecha' a Datetime para hacer las división en dos dfs\n",
    "\n",
    "df_central['Fecha'] = pd.to_datetime(df_central['Fecha'])\n",
    "\n",
    "# Dividimos el DataFrame en dos según las fechas especificas\n",
    "\n",
    "df_inicio = df_central[df_central['Fecha'] <= '2023-10-31']\n",
    "df_final = df_central[df_central['Fecha'] >= '2023-11-05']\n",
    "\n",
    "# Eliminamos la columna 'Fecha' de ambos DataFrames para poder preparar el modelo de Deep Learning\n",
    "\n",
    "df_inicio = df_inicio.drop(columns=['Fecha'])\n",
    "df_final = df_final.drop(columns=['Fecha'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19764, 8), (4942, 8), (19764,), (4942,))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preparamos df_inicio eliminando la variables objetivo del conjunto de entrenamiento (X) y especificamos la variable objetivo del conjunto de prueba (y)\n",
    "\n",
    "X = df_inicio.drop('E_SIMEL', axis=1)\n",
    "y = df_inicio['E_SIMEL']\n",
    "\n",
    "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizamos las características, paso necesario para el modelo de deep learning\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Verificamos las dimensiones de los conjuntos de datos para asegurarnos de que todo está correcto\n",
    "\n",
    "(X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "495/495 [==============================] - 2s 2ms/step - loss: 89.3838 - mae: 4.8060 - val_loss: 41.5977 - val_mae: 3.2025 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 55.8058 - mae: 3.8070 - val_loss: 42.2489 - val_mae: 3.2513 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 51.4095 - mae: 3.6352 - val_loss: 38.7833 - val_mae: 2.9453 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 51.8296 - mae: 3.6438 - val_loss: 38.5807 - val_mae: 2.8864 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 52.1989 - mae: 3.6228 - val_loss: 38.4409 - val_mae: 2.8712 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 50.2241 - mae: 3.5396 - val_loss: 37.7661 - val_mae: 2.8153 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 49.3490 - mae: 3.4850 - val_loss: 38.4868 - val_mae: 2.8956 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 48.4841 - mae: 3.4437 - val_loss: 41.7264 - val_mae: 3.1415 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 48.4080 - mae: 3.4525 - val_loss: 37.3562 - val_mae: 2.7896 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 48.8184 - mae: 3.4551 - val_loss: 37.3603 - val_mae: 2.7262 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 48.0151 - mae: 3.4171 - val_loss: 37.1923 - val_mae: 2.7606 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 47.6522 - mae: 3.4255 - val_loss: 38.3583 - val_mae: 2.9254 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 48.1505 - mae: 3.4268 - val_loss: 37.1255 - val_mae: 2.6707 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 48.2994 - mae: 3.4031 - val_loss: 38.3816 - val_mae: 2.6068 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 47.1682 - mae: 3.3991 - val_loss: 37.0153 - val_mae: 2.7533 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 47.1534 - mae: 3.3645 - val_loss: 40.0399 - val_mae: 3.0578 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 45.8378 - mae: 3.3699 - val_loss: 36.8523 - val_mae: 2.6217 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 46.8869 - mae: 3.4070 - val_loss: 36.9617 - val_mae: 2.8143 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 46.1748 - mae: 3.3553 - val_loss: 36.8467 - val_mae: 2.7742 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 46.5998 - mae: 3.3984 - val_loss: 36.5673 - val_mae: 2.6807 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 45.8443 - mae: 3.3627 - val_loss: 38.5247 - val_mae: 2.9303 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 45.3216 - mae: 3.3529 - val_loss: 36.5973 - val_mae: 2.6954 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 44.7505 - mae: 3.3296 - val_loss: 37.2454 - val_mae: 2.8472 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 45.8344 - mae: 3.3403 - val_loss: 36.8699 - val_mae: 2.7495 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 45.5478 - mae: 3.3803 - val_loss: 36.9544 - val_mae: 2.7357 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 45.1121 - mae: 3.3590 - val_loss: 38.0503 - val_mae: 2.8925 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 46.0948 - mae: 3.4008 - val_loss: 37.1591 - val_mae: 2.6030 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 45.6955 - mae: 3.3943 - val_loss: 36.5280 - val_mae: 2.7048 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 44.5599 - mae: 3.3531 - val_loss: 36.1353 - val_mae: 2.6771 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 45.1789 - mae: 3.3664 - val_loss: 36.1421 - val_mae: 2.6872 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 45.4619 - mae: 3.3856 - val_loss: 36.1324 - val_mae: 2.7731 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 45.7631 - mae: 3.3777 - val_loss: 36.1766 - val_mae: 2.7780 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 43.6835 - mae: 3.3298 - val_loss: 35.8047 - val_mae: 2.6617 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 44.0518 - mae: 3.3330 - val_loss: 36.3095 - val_mae: 2.6473 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 44.0877 - mae: 3.3384 - val_loss: 36.2088 - val_mae: 2.6171 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 45.0351 - mae: 3.3594 - val_loss: 36.0675 - val_mae: 2.6219 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 44.1511 - mae: 3.3633 - val_loss: 35.7782 - val_mae: 2.6746 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 44.7303 - mae: 3.3645 - val_loss: 35.9146 - val_mae: 2.7033 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 43.8441 - mae: 3.3725 - val_loss: 35.2870 - val_mae: 2.6068 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 43.0987 - mae: 3.3328 - val_loss: 35.9373 - val_mae: 2.7850 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 43.2242 - mae: 3.3517 - val_loss: 35.4046 - val_mae: 2.7293 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 42.9833 - mae: 3.3441 - val_loss: 35.0414 - val_mae: 2.6900 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 43.8116 - mae: 3.3426 - val_loss: 35.6411 - val_mae: 2.6508 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 43.5953 - mae: 3.3703 - val_loss: 35.9782 - val_mae: 2.7353 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 43.2291 - mae: 3.3518 - val_loss: 35.6661 - val_mae: 2.7642 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 42.7613 - mae: 3.3325 - val_loss: 35.8304 - val_mae: 2.6703 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 43.3043 - mae: 3.3574 - val_loss: 35.1025 - val_mae: 2.6678 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 42.8291 - mae: 3.3644 - val_loss: 35.7640 - val_mae: 2.7675 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 42.7309 - mae: 3.3448 - val_loss: 35.4729 - val_mae: 2.7194 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 42.7266 - mae: 3.3483 - val_loss: 34.7581 - val_mae: 2.6107 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 42.7921 - mae: 3.3356 - val_loss: 35.9838 - val_mae: 2.7938 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 40.8626 - mae: 3.2957 - val_loss: 35.1046 - val_mae: 2.6314 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.7418 - mae: 3.3197 - val_loss: 34.7837 - val_mae: 2.6841 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 42.3259 - mae: 3.3388 - val_loss: 35.5683 - val_mae: 2.7418 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 42.4179 - mae: 3.3654 - val_loss: 35.3488 - val_mae: 2.6644 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 42.3174 - mae: 3.3444 - val_loss: 34.6496 - val_mae: 2.6357 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 42.2735 - mae: 3.3621 - val_loss: 34.4589 - val_mae: 2.6149 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 42.1582 - mae: 3.3531 - val_loss: 35.1705 - val_mae: 2.6726 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 42.0294 - mae: 3.3527 - val_loss: 36.1169 - val_mae: 2.7715 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.8095 - mae: 3.3512 - val_loss: 35.0303 - val_mae: 2.7246 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.5612 - mae: 3.3319 - val_loss: 34.6890 - val_mae: 2.6241 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.4923 - mae: 3.3392 - val_loss: 35.4147 - val_mae: 2.5885 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.4057 - mae: 3.3524 - val_loss: 34.2307 - val_mae: 2.6287 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 42.0733 - mae: 3.3734 - val_loss: 34.8354 - val_mae: 2.5913 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.2292 - mae: 3.3603 - val_loss: 36.2309 - val_mae: 2.6223 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 42.3724 - mae: 3.3871 - val_loss: 34.2382 - val_mae: 2.5620 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.8978 - mae: 3.3368 - val_loss: 35.1908 - val_mae: 2.7817 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 41.2624 - mae: 3.3762 - val_loss: 34.4663 - val_mae: 2.6176 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.5177 - mae: 3.3651 - val_loss: 34.7959 - val_mae: 2.6178 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 42.1727 - mae: 3.4222 - val_loss: 34.9061 - val_mae: 2.5933 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.8359 - mae: 3.3882 - val_loss: 36.6477 - val_mae: 2.8560 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 41.7357 - mae: 3.4068 - val_loss: 36.2383 - val_mae: 2.5248 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.3626 - mae: 3.3991 - val_loss: 35.4411 - val_mae: 2.8081 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.4045 - mae: 3.3820 - val_loss: 34.6631 - val_mae: 2.5998 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.5139 - mae: 3.3932 - val_loss: 34.2555 - val_mae: 2.5741 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.6021 - mae: 3.3816 - val_loss: 34.2216 - val_mae: 2.6447 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.9148 - mae: 3.3760 - val_loss: 34.1783 - val_mae: 2.6888 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 41.8945 - mae: 3.4142 - val_loss: 37.5982 - val_mae: 2.9256 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.3839 - mae: 3.3598 - val_loss: 34.8161 - val_mae: 2.7074 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.1688 - mae: 3.3317 - val_loss: 34.4543 - val_mae: 2.7364 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.2511 - mae: 3.3978 - val_loss: 34.7563 - val_mae: 2.5578 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.8177 - mae: 3.3806 - val_loss: 34.5541 - val_mae: 2.5153 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 41.5459 - mae: 3.4130 - val_loss: 34.1645 - val_mae: 2.6199 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.9301 - mae: 3.4046 - val_loss: 35.0378 - val_mae: 2.4355 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.2958 - mae: 3.3698 - val_loss: 34.5421 - val_mae: 2.6888 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.1583 - mae: 3.4018 - val_loss: 34.8563 - val_mae: 2.7066 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.2011 - mae: 3.3660 - val_loss: 33.9690 - val_mae: 2.5884 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 39.9568 - mae: 3.3781 - val_loss: 33.7579 - val_mae: 2.5844 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.2111 - mae: 3.4105 - val_loss: 38.3059 - val_mae: 2.7269 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.7536 - mae: 3.3913 - val_loss: 34.7748 - val_mae: 2.5998 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.7281 - mae: 3.4234 - val_loss: 33.8740 - val_mae: 2.5742 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.1645 - mae: 3.4028 - val_loss: 34.2213 - val_mae: 2.6658 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 41.1923 - mae: 3.4287 - val_loss: 33.9905 - val_mae: 2.6348 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.9647 - mae: 3.4064 - val_loss: 33.9548 - val_mae: 2.4664 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.2085 - mae: 3.3947 - val_loss: 34.1953 - val_mae: 2.6577 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 41.0234 - mae: 3.4401 - val_loss: 34.6395 - val_mae: 2.6136 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 39.6859 - mae: 3.3698 - val_loss: 36.8624 - val_mae: 2.9038 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "495/495 [==============================] - 1s 1ms/step - loss: 40.4581 - mae: 3.4198 - val_loss: 34.3028 - val_mae: 2.6375 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.3951 - mae: 3.4167 - val_loss: 33.9072 - val_mae: 2.6357 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 40.1246 - mae: 3.4049 - val_loss: 34.2401 - val_mae: 2.6324 - lr: 0.0010\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 30.7240 - mae: 2.5480\n",
      "Loss en el conjunto de prueba: 30.723970413208008, MAE: 2.547966480255127\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "\n",
    "# Definimos la arquitectura del modelo, con dos capas ocultas de 64 unidades cada una con la función de activación 'relu', que proporciona\n",
    "# capacidad de modelado no lineal.\n",
    "# una capa de salida sin función de activación\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],), kernel_regularizer=regularizers.l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=25, verbose=1, mode='min', restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.001)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2, batch_size=32, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "\n",
    "\n",
    "# Evaluamos el conjunto de prueba\n",
    "\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=1)\n",
    "print(f\"Loss en el conjunto de prueba: {test_loss}, MAE: {test_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Imputador MICE entrenado con éxito.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Configuramos el imputador MICE con GradientBoostingRegressor y el estimador\n",
    "\n",
    "mice_imputer = IterativeImputer(estimator=GradientBoostingRegressor(\n",
    "                                    n_estimators=100,\n",
    "                                    max_depth=10,\n",
    "                                    min_samples_split=4,\n",
    "                                    min_samples_leaf=2,\n",
    "                                    max_features='sqrt'),\n",
    "                                    max_iter=10, random_state=42)\n",
    "\n",
    "# Preparamos los datos para el entrenamiento del imputador MICE eliminando la variable objetivo E_SIMEL\n",
    "\n",
    "X_mice = df_inicio.drop(columns=['E_SIMEL'])\n",
    "\n",
    "# Entrenamos el imputador MICE\n",
    "\n",
    "mice_imputer.fit(X_mice)\n",
    "\n",
    "# Imprimimos confirmación\n",
    "\n",
    "\"Imputador MICE entrenado con éxito.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las filas del dia 5 del df_final para hacer el tratamiento de la variable f_RUN\n",
    "\n",
    "df_final_05_11 = df_final[(df_final['Año'] == 2023) & (df_final['Mes'] == 11) & (df_final['Día'] == 5)]\n",
    "\n",
    "df_final_05_11_para_imputar = df_final_05_11.drop(['E_SIMEL'], axis=1)\n",
    "\n",
    "df_final_05_11_para_imputar[['f_RUN']] = np.nan  # Primero convertimos la columna f_RUN a NaN\n",
    "\n",
    "# En la variable creada para la imputación, predecimos los valores para las columnas siguientes\n",
    "\n",
    "valores_imputados = mice_imputer.transform(df_final_05_11_para_imputar[['Period', 'PREVISION', 'f_RUN', 'Dia_Semana', 'Es_fin_semana', 'Año', 'Mes', 'Día']])\n",
    "\n",
    "# Realmente solo queremos imputar la columna f_RUN, por lo tanto cogemos solo los valores imputados a la columna en concreto y\n",
    "# establecemos una condición que si los valores son más grandes que 0.2 establecemos un 1, y si son inferiores establecemos un 0.\n",
    "\n",
    "valores_imputados_f_RUN = np.where(valores_imputados[:, 2]> 0.2, 1, 0)\n",
    "\n",
    "df_final_05_11.loc[:, 'f_RUN'] = valores_imputados_f_RUN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.21490622],\n",
       "       [0.34728146],\n",
       "       [0.33934116],\n",
       "       [0.3314004 ],\n",
       "       [0.30388498],\n",
       "       [0.2760558 ],\n",
       "       [0.2592516 ],\n",
       "       [0.2417326 ],\n",
       "       [0.22439814],\n",
       "       [0.21672678],\n",
       "       [0.21275568],\n",
       "       [0.22775507],\n",
       "       [0.27858782],\n",
       "       [9.247498  ],\n",
       "       [8.859642  ],\n",
       "       [8.496704  ],\n",
       "       [8.136265  ],\n",
       "       [7.708955  ],\n",
       "       [7.202019  ],\n",
       "       [5.3416247 ],\n",
       "       [0.7198763 ],\n",
       "       [0.7693553 ],\n",
       "       [0.82098913]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparamos los datos de df_final_05_11 para la predicción quitando la variable objetivo\n",
    "\n",
    "X_final_05_11 = df_final_05_11.drop(['E_SIMEL'], axis=1)\n",
    "\n",
    "# Normalización de los datos\n",
    "\n",
    "X_final_05_11_scaled = scaler.transform(X_final_05_11)\n",
    "\n",
    "# Realizamos la predicciones de E_SIMEL con el modelo de deep learning\n",
    "\n",
    "e_simel_predicciones = model.predict(X_final_05_11_scaled)\n",
    "\n",
    "e_simel_predicciones = np.maximum(e_simel_predicciones, 0)\n",
    "\n",
    "# Mostramos los resultados de la predicción\n",
    "\n",
    "e_simel_predicciones[:25]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 10\\AppData\\Local\\Temp\\ipykernel_72268\\496075226.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final_05_11['Prediccion_E_SIMEL'] = predicciones_lista\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_SIMEL</th>\n",
       "      <th>PREVISION</th>\n",
       "      <th>Prediccion_E_SIMEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24802</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24803</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24804</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24805</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24806</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24807</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24808</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24809</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24810</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24811</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24812</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24813</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24814</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24815</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24816</th>\n",
       "      <td>4.122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.247498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817</th>\n",
       "      <td>5.437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.859642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24818</th>\n",
       "      <td>6.378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.496704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24819</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.136265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24820</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.708955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24821</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.202019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24822</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.341625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24823</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24824</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24825</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       E_SIMEL  PREVISION  Prediccion_E_SIMEL\n",
       "24802    0.000        0.0            0.000000\n",
       "24803    0.000        0.0            0.214906\n",
       "24804    0.000        0.0            0.347281\n",
       "24805    0.000        0.0            0.339341\n",
       "24806    0.000        0.0            0.331400\n",
       "24807    0.000        0.0            0.303885\n",
       "24808    0.000        0.0            0.276056\n",
       "24809    0.000        0.0            0.259252\n",
       "24810    0.000        0.0            0.241733\n",
       "24811    0.000        0.0            0.224398\n",
       "24812    0.000        0.0            0.216727\n",
       "24813    0.000        0.0            0.212756\n",
       "24814    0.000        0.0            0.227755\n",
       "24815    0.000        0.0            0.278588\n",
       "24816    4.122        0.0            9.247498\n",
       "24817    5.437        0.0            8.859642\n",
       "24818    6.378        0.0            8.496704\n",
       "24819    0.000        0.0            8.136265\n",
       "24820    0.000        0.0            7.708955\n",
       "24821    0.000        0.0            7.202019\n",
       "24822    0.000        0.0            5.341625\n",
       "24823    0.000        0.0            0.719876\n",
       "24824    0.000        0.0            0.769355\n",
       "24825    0.000        0.0            0.820989"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertimos el array a una lista para facilitar la asignación a una nueva columna que llamamos 'Prediccion_E_SIMEL'\n",
    "\n",
    "predicciones_lista = e_simel_predicciones.flatten().tolist()\n",
    "\n",
    "# Asignar las predicciones a df_final_05_11\n",
    "\n",
    "df_final_05_11['Prediccion_E_SIMEL'] = predicciones_lista\n",
    "\n",
    "# Mostramos las primeras filas para verificar\n",
    "\n",
    "df_final_05_11[['E_SIMEL', 'PREVISION', 'Prediccion_E_SIMEL']].head(25)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma real:  15.937000000000001\n",
      "Suma predicha:  60.777005672454834\n",
      "Desviación porcentual:  281.35788211366526 %\n",
      "Suma previsión:  0.0\n",
      "Desviación porcentual:  -100.0 %\n"
     ]
    }
   ],
   "source": [
    "# al igual que en todos los casos anteriores, hacemos un sumatorio y porcentaje de desviación para tener una primera idea de como van las predicciones\n",
    "\n",
    "suma_real_05 = df_final_05_11['E_SIMEL'].sum()\n",
    "suma_predicha_05 = df_final_05_11['Prediccion_E_SIMEL'].sum()\n",
    "suma_prevision_05 = df_final_05_11['PREVISION'].sum()\n",
    "\n",
    "\n",
    "if suma_real_05 != 0:\n",
    "    desviacion_porcentual = 100 * (suma_predicha_05 - suma_real_05) / suma_real_05\n",
    "else:\n",
    "    desviacion_porcentual = float('inf')  # en caso de división por cero, retorna un valor especial para que no nos dé error\n",
    "\n",
    "\n",
    "\n",
    "if suma_real_05 != 0:\n",
    "    desviacion_porcentual_prevision = 100 * (suma_prevision_05 - suma_real_05) / suma_real_05\n",
    "else:\n",
    "    desviacion_porcentual_prevision = float('inf')  # en caso de división por cero, retorna un valor especial para que no nos dé error\n",
    "\n",
    "print(\"Suma real: \", suma_real_05)\n",
    "print(\"Suma predicha: \", suma_predicha_05)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual, \"%\")\n",
    "print(\"Suma previsión: \", suma_prevision_05)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual_prevision, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "619/619 [==============================] - 1s 2ms/step - loss: 37.7662 - mae: 3.2514 - val_loss: 41.4291 - val_mae: 3.3071 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 37.3600 - mae: 3.2263 - val_loss: 47.4276 - val_mae: 3.8756 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 37.4137 - mae: 3.2307 - val_loss: 44.2947 - val_mae: 3.5394 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 37.5549 - mae: 3.2209 - val_loss: 48.8770 - val_mae: 3.7361 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.9402 - mae: 3.2086 - val_loss: 47.0773 - val_mae: 3.6067 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.9625 - mae: 3.2151 - val_loss: 55.3712 - val_mae: 4.0188 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.3267 - mae: 3.1966 - val_loss: 52.4463 - val_mae: 3.8418 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.2201 - mae: 3.1893 - val_loss: 53.3662 - val_mae: 3.9959 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.6829 - mae: 3.2088 - val_loss: 50.5138 - val_mae: 3.9245 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.6930 - mae: 3.2126 - val_loss: 54.7623 - val_mae: 3.9353 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.2261 - mae: 3.1891 - val_loss: 55.1304 - val_mae: 3.9633 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "619/619 [==============================] - 1s 2ms/step - loss: 36.1666 - mae: 3.1928 - val_loss: 55.1591 - val_mae: 4.0344 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 37.3794 - mae: 3.2396 - val_loss: 56.9595 - val_mae: 4.0601 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.8216 - mae: 3.2362 - val_loss: 52.4048 - val_mae: 3.8521 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.2068 - mae: 3.2070 - val_loss: 63.0613 - val_mae: 4.2814 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.8826 - mae: 3.2062 - val_loss: 64.1609 - val_mae: 4.3992 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.0175 - mae: 3.1807 - val_loss: 62.7114 - val_mae: 4.2515 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.2393 - mae: 3.1940 - val_loss: 65.0689 - val_mae: 4.3883 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.3886 - mae: 3.2066 - val_loss: 59.5122 - val_mae: 4.2399 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.0647 - mae: 3.1988 - val_loss: 62.2163 - val_mae: 4.2776 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 35.8084 - mae: 3.1850 - val_loss: 63.6467 - val_mae: 4.4524 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.0285 - mae: 3.1943 - val_loss: 61.1567 - val_mae: 4.1897 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.6406 - mae: 3.2287 - val_loss: 57.8380 - val_mae: 4.0760 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 35.7789 - mae: 3.1992 - val_loss: 61.5313 - val_mae: 4.2957 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.5935 - mae: 3.2223 - val_loss: 69.5927 - val_mae: 4.5828 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "590/619 [===========================>..] - ETA: 0s - loss: 36.1453 - mae: 3.2171Restoring model weights from the end of the best epoch: 1.\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.3654 - mae: 3.2250 - val_loss: 76.7742 - val_mae: 4.8665 - lr: 0.0010\n",
      "Epoch 26: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IterativeImputer(estimator=GradientBoostingRegressor(max_depth=10,\n",
       "                                                     max_features=&#x27;sqrt&#x27;,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=4),\n",
       "                 random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IterativeImputer</label><div class=\"sk-toggleable__content\"><pre>IterativeImputer(estimator=GradientBoostingRegressor(max_depth=10,\n",
       "                                                     max_features=&#x27;sqrt&#x27;,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=4),\n",
       "                 random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=10, max_features=&#x27;sqrt&#x27;, min_samples_leaf=2,\n",
       "                          min_samples_split=4)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=10, max_features=&#x27;sqrt&#x27;, min_samples_leaf=2,\n",
       "                          min_samples_split=4)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "IterativeImputer(estimator=GradientBoostingRegressor(max_depth=10,\n",
       "                                                     max_features='sqrt',\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=4),\n",
       "                 random_state=42)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Una vez tenemos la primera predicción, actualizamos df_inicio con los datos del día 5. Así estamos simulando como sería\n",
    "# el proceso de predicción en tiempo real\n",
    "\n",
    "datos_dia_5 = df_final[(df_final['Año'] == 2023) & (df_final['Mes'] == 11) & (df_final['Día'] == 5)]\n",
    "df_inicio_actualizado = pd.concat([df_inicio, datos_dia_5])\n",
    "\n",
    "# Preparamos df_actualizado con los datos de df_inicio y los datos del día 5 para reentrenar el modelo de deep learning\n",
    "\n",
    "X_actualizado = df_inicio_actualizado.drop('E_SIMEL', axis=1)\n",
    "y_actualizado = df_inicio_actualizado['E_SIMEL']\n",
    "\n",
    "\n",
    "# Normalizamos con fit_transform\n",
    "\n",
    "X_total_scaled = scaler.fit_transform(X_actualizado)  # Utilizamos fit_transform \n",
    "\n",
    "# Y reentrenamos el modelo de deep learning con todos los datos con los parámetros utilizados para el entrenamiento inicial\n",
    "\n",
    "model.fit(X_total_scaled, y_actualizado, epochs=100, validation_split=0.2, batch_size=32, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "\n",
    "# reentrenamos también el modelo imputador con los nuevos datos con todas las variables menos con E_SIMEL\n",
    "\n",
    "mice_imputer.fit(df_inicio_actualizado[['Period', 'PREVISION', 'f_RUN', 'Dia_Semana', 'Es_fin_semana', 'Año', 'Mes', 'Día']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 10\\AppData\\Local\\Temp\\ipykernel_72268\\3222644168.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final_06_11['Prediccion_E_SIMEL'] = predicciones_lista\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_SIMEL</th>\n",
       "      <th>PREVISION</th>\n",
       "      <th>Prediccion_E_SIMEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24826</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24827</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24828</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24829</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24830</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24831</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24832</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24833</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24834</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24835</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24836</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.260181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24837</th>\n",
       "      <td>0.000</td>\n",
       "      <td>11.6</td>\n",
       "      <td>11.572828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24838</th>\n",
       "      <td>0.000</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.030605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24839</th>\n",
       "      <td>0.000</td>\n",
       "      <td>19.4</td>\n",
       "      <td>14.995148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24840</th>\n",
       "      <td>3.946</td>\n",
       "      <td>24.3</td>\n",
       "      <td>15.376371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24841</th>\n",
       "      <td>22.905</td>\n",
       "      <td>29.8</td>\n",
       "      <td>15.927568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24842</th>\n",
       "      <td>21.310</td>\n",
       "      <td>32.9</td>\n",
       "      <td>16.040432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24843</th>\n",
       "      <td>9.663</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.423210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24844</th>\n",
       "      <td>0.718</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.575287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24845</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24846</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24847</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24848</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24849</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       E_SIMEL  PREVISION  Prediccion_E_SIMEL\n",
       "24826    0.000        0.0            0.000000\n",
       "24827    0.000        0.0            0.204602\n",
       "24828    0.000        0.0            0.226279\n",
       "24829    0.000        0.0            0.192582\n",
       "24830    0.000        0.0            0.160977\n",
       "24831    0.000        0.0            0.138354\n",
       "24832    0.000        0.0            0.115732\n",
       "24833    0.000        0.0            0.093109\n",
       "24834    0.000        0.0            0.076867\n",
       "24835    0.000        0.0            0.050153\n",
       "24836    0.000        2.6            3.260181\n",
       "24837    0.000       11.6           11.572828\n",
       "24838    0.000       15.8           15.030605\n",
       "24839    0.000       19.4           14.995148\n",
       "24840    3.946       24.3           15.376371\n",
       "24841   22.905       29.8           15.927568\n",
       "24842   21.310       32.9           16.040432\n",
       "24843    9.663       19.0           10.423210\n",
       "24844    0.718        4.0            7.575287\n",
       "24845    0.000        0.0            0.000000\n",
       "24846    0.000        0.0            0.036900\n",
       "24847    0.000        0.0            0.094171\n",
       "24848    0.000        0.0            0.164499\n",
       "24849    0.000        0.0            0.240213"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Seleccionamos las filas del dia 6 del df_final para hacer el tratamiento de la variable f_RUN\n",
    "\n",
    "df_final_06_11 = df_final[(df_final['Año'] == 2023) & (df_final['Mes'] == 11) & (df_final['Día'] == 6)]\n",
    "\n",
    "df_final_06_11_para_imputar = df_final_06_11.drop(['E_SIMEL'], axis=1)\n",
    "\n",
    "df_final_06_11_para_imputar[['f_RUN']] = np.nan  # Primero convertimos la columna f_RUN a NaN\n",
    "\n",
    "# En la variable creada para la imputación, predecimos los valores para las columnas siguientes\n",
    "\n",
    "valores_imputados = mice_imputer.transform(df_final_06_11_para_imputar[['Period', 'PREVISION', 'f_RUN', 'Dia_Semana', 'Es_fin_semana', 'Año', 'Mes', 'Día']])\n",
    "\n",
    "# Realmente solo queremos imputar la columna f_RUN, por lo tanto cogemos solo los valores imputados a la columna en concreto\n",
    "\n",
    "valores_imputados_f_RUN = np.where(valores_imputados[:, 2]> 0.2, 1, 0)\n",
    "\n",
    "df_final_06_11.loc[:, 'f_RUN'] = valores_imputados_f_RUN\n",
    "\n",
    "\n",
    "# Verificamos que los valores han sido imputados correctamente\n",
    "# df_final_05_11.head(25)\n",
    "\n",
    "# Prepararamos los datos de df_final_06_11 para la predicción\n",
    "\n",
    "X_final_06_11 = df_final_06_11.drop(['E_SIMEL'], axis=1)\n",
    "\n",
    "# Normalizamos los datos de X_final_05_11 \n",
    "\n",
    "X_final_06_11_scaled = scaler.transform(X_final_06_11)\n",
    "\n",
    "# Realizamos las predicciones de E_SIMEL\n",
    "\n",
    "e_simel_predicciones_06 = model.predict(X_final_06_11_scaled)\n",
    "\n",
    "# Para que no haya valores negativos los transformamos a cero\n",
    "\n",
    "e_simel_predicciones_06 = np.maximum(e_simel_predicciones_06, 0)\n",
    "\n",
    "# Mostrar las primeras 5 predicciones\n",
    "# e_simel_predicciones[:25]\n",
    "\n",
    "# Convertimos el array de predicciones a una lista para facilitar la asignación\n",
    "\n",
    "predicciones_lista = e_simel_predicciones_06.flatten().tolist()\n",
    "\n",
    "# Asignamos las predicciones a una nueva columna en el Datadrame df_final_06_11\n",
    "\n",
    "df_final_06_11['Prediccion_E_SIMEL'] = predicciones_lista\n",
    "\n",
    "# Visualizamos las columnas para ver el resultado\n",
    "\n",
    "df_final_06_11[['E_SIMEL', 'PREVISION', 'Prediccion_E_SIMEL']].head(25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma real:  58.542\n",
      "Suma predicha:  111.9960675239563\n",
      "Desviación porcentual:  91.3089192783921 %\n",
      "Suma previsión:  159.4\n",
      "Desviación porcentual:  172.2831471422227 %\n"
     ]
    }
   ],
   "source": [
    "# Sumatorios y porcentajes de desviación\n",
    "\n",
    "suma_real_06 = df_final_06_11['E_SIMEL'].sum()\n",
    "suma_predicha_06 = df_final_06_11['Prediccion_E_SIMEL'].sum()\n",
    "suma_prevision_06 = df_final_06_11['PREVISION'].sum()\n",
    "\n",
    "\n",
    "if suma_real_06 != 0:\n",
    "    desviacion_porcentual = 100 * (suma_predicha_06 - suma_real_06) / suma_real_06\n",
    "else:\n",
    "    desviacion_porcentual = float('inf')  # en caso de división por cero, retorna un valor especial para que no nos dé error\n",
    "\n",
    "\n",
    "\n",
    "if suma_real_06 != 0:\n",
    "    desviacion_porcentual_prevision = 100 * (suma_prevision_06 - suma_real_06) / suma_real_06\n",
    "else:\n",
    "    desviacion_porcentual_prevision = float('inf')  # en caso de división por cero, retorna un valor especial para que no nos dé error\n",
    "\n",
    "print(\"Suma real: \", suma_real_06)\n",
    "print(\"Suma predicha: \", suma_predicha_06)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual, \"%\")\n",
    "print(\"Suma previsión: \", suma_prevision_06)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual_prevision, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un función para agilizar el proceso de actualización, reentreno de los modelos, imputación, predicción y cálculo de las métricas\n",
    "\n",
    "def predecir_y_actualizar_para_un_dia(dia_actual, dia_siguiente,  mes, año, df_inicio_actualizado, df_final, modelo_deep, imputador):\n",
    "    \"\"\"\n",
    "    Función para actualizar el conjunto de entrenamiento con los datos reales de un día específico,\n",
    "    realizar la imputación para el día siguiente y predecir los valores de E_SIMEL para ese día.\n",
    "\n",
    "    Args:\n",
    "    dia_actual (int): Día actual para el que se actualizarán los datos.\n",
    "    dia_siguiente (int): Datos del día que queremos hacer las imputaciones y la predicción\n",
    "    mes (int): Mes del día actual.\n",
    "    ano (int): Año del día actual.\n",
    "    df_inicio_actualizado (DataFrame): DataFrame actualizado con los datos hasta el día anterior.\n",
    "    df_final (DataFrame): DataFrame con los datos a predecir.\n",
    "    modelo_deep (DeepLearning de TencerFlow): Modelo de Deep Learning entrenado.\n",
    "    imputador (IterativeImputer): Imputador MICE entrenado.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: DataFrame con las predicciones para el día siguiente.\n",
    "    DataFrame: DataFrame actualizado con los datos reales del día actual.\n",
    "    \"\"\"\n",
    "    # Actualización de df_actualizado con los datos de dia_actual\n",
    "\n",
    "    datos_dia_actual = df_final[(df_final['Año'] == año) & (df_final['Mes'] == mes) & (df_final['Día'] == dia_actual)]\n",
    "    df_inicio_actualizado = pd.concat([df_inicio_actualizado, datos_dia_actual])\n",
    "\n",
    "    \n",
    "    # Prepararamos los datos para el modelo de deep learning\n",
    "\n",
    "    X_actualizado = df_inicio_actualizado.drop('E_SIMEL', axis=1)\n",
    "    y_actualizado = df_inicio_actualizado['E_SIMEL']\n",
    "\n",
    "        \n",
    "    # Normalizaación las características\n",
    "\n",
    "    X_actualizado_scaled = scaler.transform(X_actualizado)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=25, verbose=1, mode='min', restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.001)\n",
    "\n",
    "    # Reentrenamos el modelo de deep learning con todos los datos pasándole los parámetros de modelado\n",
    "\n",
    "    modelo_deep.fit(X_actualizado_scaled, y_actualizado, epochs=100, validation_split=0.2, batch_size=32, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "\n",
    "    # Reentrenamos el imputador para todas las variables menos con E_SIMEL\n",
    "\n",
    "    imputador.fit(df_inicio_actualizado[['Period', 'PREVISION', 'f_RUN', 'Dia_Semana', 'Es_fin_semana', 'Año', 'Mes', 'Día']])    \n",
    "\n",
    "    \n",
    "\n",
    "      # Imputación de valores a la columna f_RUN para la predicción\n",
    "\n",
    "    df_dia_siguiente = df_final[(df_final['Año'] == año) & (df_final['Mes'] == mes) & (df_final['Día'] == dia_siguiente)]\n",
    "    df_dia_siguiente_para_imputar = df_dia_siguiente.drop(['E_SIMEL'], axis=1)\n",
    "    df_dia_siguiente_para_imputar[['f_RUN']] = np.nan  \n",
    "    \n",
    "    valores_imputados = imputador.transform(df_dia_siguiente_para_imputar)\n",
    "    \n",
    "    df_dia_siguiente.loc[:, 'f_RUN'] = np.where(valores_imputados[:, 2] > 0.2, 1, 0) \n",
    "\n",
    "    \n",
    "    \n",
    "    # Preparamos los datos para la predicción con el modelo de deep learning\n",
    "\n",
    "    X_prediccion = df_dia_siguiente.drop(['E_SIMEL'], axis=1)\n",
    "\n",
    "    # Normalizamos los datos \n",
    "\n",
    "    X_prediccion_scaled = scaler.transform(X_prediccion)\n",
    "\n",
    "    # Realizamos las predicciones de E_SIMEL\n",
    "    predicted_e_simel = model.predict(X_prediccion_scaled)\n",
    "\n",
    "    # Transformamos los valores negativos de la predicción a cero\n",
    "\n",
    "    predicted_e_simel = np.maximum(predicted_e_simel, 0)\n",
    "\n",
    "    # Mostramos las predicciones\n",
    "\n",
    "    # e_simel_predicciones[:25]\n",
    "\n",
    "    # Convertimos el array de las predicciones a una lista para facilitar la asignación\n",
    "    predicciones_lista = predicted_e_simel.flatten().tolist()\n",
    "\n",
    "    df_predicciones = df_dia_siguiente[['Año', 'Mes', 'Día', 'PREVISION', 'E_SIMEL']].copy()\n",
    "\n",
    "    # En el df_prediciones creamos una nueva columna con las predicciones\n",
    "\n",
    "    df_predicciones['Prediccion_E_SIMEL'] = predicciones_lista\n",
    "\n",
    "    # Mostramos el resultado\n",
    "\n",
    "    df_predicciones[['E_SIMEL', 'PREVISION', 'Prediccion_E_SIMEL']].head(25)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Calculamos las métricas: mse (Error cuadrático medio), r2 (coeficiente de determinación) y el mae(error medio absoluto)\n",
    "\n",
    "    mse = mean_squared_error(df_predicciones['E_SIMEL'], df_predicciones['Prediccion_E_SIMEL'])\n",
    "    r2 = r2_score(df_predicciones['E_SIMEL'], df_predicciones['Prediccion_E_SIMEL'])\n",
    "    mae = mean_absolute_error(df_predicciones['E_SIMEL'], df_predicciones['Prediccion_E_SIMEL'])\n",
    "\n",
    "\n",
    "    return df_predicciones, df_inicio_actualizado, mse, r2, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "619/619 [==============================] - 1s 2ms/step - loss: 37.2893 - mae: 3.2148 - val_loss: 45.1692 - val_mae: 3.5512 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 37.0058 - mae: 3.2114 - val_loss: 49.4829 - val_mae: 3.7362 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 37.1679 - mae: 3.2269 - val_loss: 46.6995 - val_mae: 3.5558 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 37.2355 - mae: 3.2277 - val_loss: 54.4792 - val_mae: 3.8986 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.6911 - mae: 3.2239 - val_loss: 57.7612 - val_mae: 4.1846 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.7420 - mae: 3.1964 - val_loss: 71.0054 - val_mae: 4.7679 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 37.7519 - mae: 3.2320 - val_loss: 60.8240 - val_mae: 4.3351 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "619/619 [==============================] - 1s 2ms/step - loss: 36.8207 - mae: 3.2322 - val_loss: 65.8175 - val_mae: 4.3702 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "619/619 [==============================] - 1s 2ms/step - loss: 36.9093 - mae: 3.2092 - val_loss: 64.6847 - val_mae: 4.4204 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 37.0709 - mae: 3.2308 - val_loss: 55.9455 - val_mae: 4.0375 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.7434 - mae: 3.2035 - val_loss: 59.3257 - val_mae: 4.1745 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.5160 - mae: 3.2084 - val_loss: 63.6599 - val_mae: 4.2967 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.7137 - mae: 3.2269 - val_loss: 58.6260 - val_mae: 4.1504 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.9938 - mae: 3.2267 - val_loss: 62.9459 - val_mae: 4.2381 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.3775 - mae: 3.1938 - val_loss: 67.7572 - val_mae: 4.4869 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.4053 - mae: 3.1977 - val_loss: 66.6004 - val_mae: 4.4789 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.8080 - mae: 3.2283 - val_loss: 57.0372 - val_mae: 4.0907 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "619/619 [==============================] - 1s 2ms/step - loss: 36.0456 - mae: 3.1702 - val_loss: 69.4167 - val_mae: 4.6013 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 37.0847 - mae: 3.2358 - val_loss: 76.6842 - val_mae: 4.8623 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.6205 - mae: 3.2253 - val_loss: 75.8132 - val_mae: 4.6508 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.5241 - mae: 3.2339 - val_loss: 64.4720 - val_mae: 4.2709 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.7027 - mae: 3.2243 - val_loss: 72.9734 - val_mae: 4.5154 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.4122 - mae: 3.2142 - val_loss: 70.0153 - val_mae: 4.6463 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 35.8192 - mae: 3.1832 - val_loss: 63.9930 - val_mae: 4.4719 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.1582 - mae: 3.2074 - val_loss: 75.6685 - val_mae: 4.8646 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "586/619 [===========================>..] - ETA: 0s - loss: 36.3480 - mae: 3.2196Restoring model weights from the end of the best epoch: 1.\n",
      "619/619 [==============================] - 1s 1ms/step - loss: 36.2194 - mae: 3.2080 - val_loss: 72.6097 - val_mae: 4.6999 - lr: 0.0010\n",
      "Epoch 26: early stopping\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "MSE: 33.57476737042998 R²: 0.15771091005852533 MAE: 3.4864182435671487\n"
     ]
    }
   ],
   "source": [
    "# Llamamos a la función\n",
    "\n",
    "dia_actual = 6    # Actualización de datos con los que reentrenamos los modelos\n",
    "dia_siguiente = 7    # Preparación de datos para la imputación y predicción\n",
    "df_predicciones_07_11, df_inicio_actualizado, mse_07_11, r2_07_11, mae_07_11 = predecir_y_actualizar_para_un_dia(dia_actual, dia_siguiente, 11, 2023, df_inicio_actualizado, df_final, model, mice_imputer)\n",
    "print(\"MSE:\", mse_07_11, \"R²:\", r2_07_11, \"MAE:\", mae_07_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma real:  67.97999999999999\n",
      "Suma predicha:  74.83839845657349\n",
      "Desviación porcentual:  10.088847391252571 %\n",
      "Suma previsión:  24.0\n",
      "Desviación porcentual:  -64.6954986760812 %\n"
     ]
    }
   ],
   "source": [
    "# Y como en la predicción anterior calculamos los sumatorios y los porcentajes de desviación\n",
    "\n",
    "suma_real_07_11 = df_predicciones_07_11['E_SIMEL'].sum()\n",
    "suma_predicha_07_11 = df_predicciones_07_11['Prediccion_E_SIMEL'].sum()\n",
    "suma_prevision_07_11 = df_predicciones_07_11['PREVISION'].sum()\n",
    "\n",
    "\n",
    "if suma_real_07_11 != 0:\n",
    "    desviacion_porcentual = 100 * (suma_predicha_07_11 - suma_real_07_11) / suma_real_07_11\n",
    "else:\n",
    "    desviacion_porcentual = float('inf')  \n",
    "\n",
    "\n",
    "\n",
    "if suma_real_07_11 != 0:\n",
    "    desviacion_porcentual_prevision = 100 * (suma_prevision_07_11 - suma_real_07_11) / suma_real_07_11\n",
    "else:\n",
    "    desviacion_porcentual_prevision = float('inf')  \n",
    "    \n",
    "\n",
    "print(\"Suma real: \", suma_real_07_11)\n",
    "print(\"Suma predicha: \", suma_predicha_07_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual, \"%\")\n",
    "print(\"Suma previsión: \", suma_prevision_07_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual_prevision, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 37.0623 - mae: 3.2158 - val_loss: 44.6343 - val_mae: 3.4928 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 37.0104 - mae: 3.2055 - val_loss: 55.5635 - val_mae: 4.2017 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.6546 - mae: 3.2052 - val_loss: 48.4874 - val_mae: 3.7553 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 37.8237 - mae: 3.2601 - val_loss: 49.5633 - val_mae: 3.8691 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.6038 - mae: 3.1920 - val_loss: 53.4723 - val_mae: 4.0307 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.4080 - mae: 3.1915 - val_loss: 60.0158 - val_mae: 4.3632 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 36.9793 - mae: 3.2165 - val_loss: 58.3388 - val_mae: 4.1330 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 37.7105 - mae: 3.2310 - val_loss: 68.0280 - val_mae: 4.5908 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.1732 - mae: 3.1774 - val_loss: 65.0633 - val_mae: 4.4603 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.3315 - mae: 3.1976 - val_loss: 66.9791 - val_mae: 4.4872 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.7858 - mae: 3.2249 - val_loss: 59.3383 - val_mae: 4.1774 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 37.1772 - mae: 3.2377 - val_loss: 61.6998 - val_mae: 4.2723 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.3666 - mae: 3.2113 - val_loss: 62.0374 - val_mae: 4.3046 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.6496 - mae: 3.2120 - val_loss: 58.6184 - val_mae: 4.0076 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 37.4568 - mae: 3.2430 - val_loss: 66.3442 - val_mae: 4.4702 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.3508 - mae: 3.1929 - val_loss: 78.3934 - val_mae: 4.9987 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.4732 - mae: 3.2172 - val_loss: 62.3158 - val_mae: 4.2086 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.6864 - mae: 3.2328 - val_loss: 79.7162 - val_mae: 4.8811 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 35.7777 - mae: 3.2095 - val_loss: 66.8946 - val_mae: 4.3612 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.3194 - mae: 3.2319 - val_loss: 67.2509 - val_mae: 4.5401 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 35.6729 - mae: 3.1958 - val_loss: 79.5187 - val_mae: 4.8393 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 37.1346 - mae: 3.2409 - val_loss: 82.3262 - val_mae: 5.0205 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 36.0116 - mae: 3.2029 - val_loss: 78.7013 - val_mae: 4.9688 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.3347 - mae: 3.2293 - val_loss: 71.8373 - val_mae: 4.5159 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "620/620 [==============================] - 1s 1ms/step - loss: 36.3784 - mae: 3.2348 - val_loss: 65.8440 - val_mae: 4.4748 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "590/620 [===========================>..] - ETA: 0s - loss: 36.0968 - mae: 3.2317Restoring model weights from the end of the best epoch: 1.\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 36.0741 - mae: 3.2321 - val_loss: 63.4258 - val_mae: 4.2559 - lr: 0.0010\n",
      "Epoch 26: early stopping\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "MSE: 22.43247614291161 R²: -6.385157378073937 MAE: 2.370632844289144\n"
     ]
    }
   ],
   "source": [
    "# Llamamos a la función. Actualización de datos reales del día 7 para reentrenar los modelos\n",
    "# Preparación de los datos del día posterior, en este caso del día 8, para la imputación y predicción\n",
    "\n",
    "dia_actual = 7\n",
    "dia_siguiente = 8\n",
    "\n",
    "df_predicciones_08_11, df_inicio_actualizado, mse_08_11, r2_08_11, mae_08_11 = predecir_y_actualizar_para_un_dia(dia_actual, dia_siguiente, 11, 2023, df_inicio_actualizado, df_final, model, mice_imputer)\n",
    "print(\"MSE:\", mse_08_11, \"R²:\", r2_08_11, \"MAE:\", mae_08_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma real:  11.296999999999999\n",
      "Suma predicha:  68.19218826293945\n",
      "Desviación porcentual:  503.6309485964368 %\n",
      "Suma previsión:  0.0\n",
      "Desviación porcentual:  -100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Sumatorios y porcentajes\n",
    "\n",
    "suma_real_08_11 = df_predicciones_08_11['E_SIMEL'].sum()\n",
    "suma_predicha_08_11 = df_predicciones_08_11['Prediccion_E_SIMEL'].sum()\n",
    "suma_prevision_08_11 = df_predicciones_08_11['PREVISION'].sum()\n",
    "\n",
    "\n",
    "if suma_real_08_11 != 0:\n",
    "    desviacion_porcentual = 100 * (suma_predicha_08_11 - suma_real_08_11) / suma_real_08_11\n",
    "else:\n",
    "    desviacion_porcentual = float('inf')  \n",
    "\n",
    "\n",
    "\n",
    "if suma_real_08_11 != 0:\n",
    "    desviacion_porcentual_prevision = 100 * (suma_prevision_08_11 - suma_real_08_11) / suma_real_08_11\n",
    "else:\n",
    "    desviacion_porcentual_prevision = float('inf')  \n",
    "    \n",
    "\n",
    "print(\"Suma real: \", suma_real_08_11)\n",
    "print(\"Suma predicha: \", suma_predicha_08_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual, \"%\")\n",
    "print(\"Suma previsión: \", suma_prevision_08_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual_prevision, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 36.6965 - mae: 3.1984 - val_loss: 51.1555 - val_mae: 3.9443 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 37.0854 - mae: 3.2236 - val_loss: 51.4634 - val_mae: 3.8962 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.7944 - mae: 3.2153 - val_loss: 50.3702 - val_mae: 3.7339 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.9650 - mae: 3.2309 - val_loss: 51.1323 - val_mae: 3.7002 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.4193 - mae: 3.1897 - val_loss: 53.5188 - val_mae: 3.8856 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.3971 - mae: 3.2020 - val_loss: 63.0759 - val_mae: 4.2346 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 37.0889 - mae: 3.2388 - val_loss: 59.6823 - val_mae: 4.1376 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.6966 - mae: 3.2246 - val_loss: 51.6516 - val_mae: 3.7170 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 37.4437 - mae: 3.2486 - val_loss: 56.0082 - val_mae: 3.8892 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.5751 - mae: 3.2010 - val_loss: 64.8572 - val_mae: 4.3288 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.7143 - mae: 3.2189 - val_loss: 73.3438 - val_mae: 4.6245 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 36.3115 - mae: 3.2080 - val_loss: 82.1358 - val_mae: 4.9058 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.7600 - mae: 3.2458 - val_loss: 87.0985 - val_mae: 5.0578 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.8373 - mae: 3.2241 - val_loss: 74.1471 - val_mae: 4.5622 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.9768 - mae: 3.2613 - val_loss: 84.7043 - val_mae: 4.9790 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 35.7558 - mae: 3.1824 - val_loss: 90.6581 - val_mae: 5.1543 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 35.5842 - mae: 3.1552 - val_loss: 68.6799 - val_mae: 4.4164 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.6638 - mae: 3.2392 - val_loss: 70.4759 - val_mae: 4.4184 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 35.7028 - mae: 3.2024 - val_loss: 84.3528 - val_mae: 5.0069 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 35.0768 - mae: 3.1860 - val_loss: 74.8702 - val_mae: 4.6317 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.6685 - mae: 3.2327 - val_loss: 83.1562 - val_mae: 4.9315 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.0947 - mae: 3.2332 - val_loss: 73.5088 - val_mae: 4.5073 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.1742 - mae: 3.2138 - val_loss: 77.6712 - val_mae: 4.7752 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.1912 - mae: 3.2196 - val_loss: 70.2793 - val_mae: 4.4601 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.2896 - mae: 3.2275 - val_loss: 82.0186 - val_mae: 4.8476 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 35.8453 - mae: 3.2222 - val_loss: 71.4688 - val_mae: 4.5292 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.2376 - mae: 3.2265 - val_loss: 67.6327 - val_mae: 4.4302 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "616/621 [============================>.] - ETA: 0s - loss: 35.5298 - mae: 3.1971Restoring model weights from the end of the best epoch: 3.\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 35.5661 - mae: 3.1997 - val_loss: 61.6703 - val_mae: 4.1130 - lr: 0.0010\n",
      "Epoch 28: early stopping\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "MSE: 37.11501885180945 R²: 0.6031359909056068 MAE: 3.1643504964510605\n"
     ]
    }
   ],
   "source": [
    "# Seguimos con el mismo proceso anterior. Llamamos a la función con los días específicos que queremos actualizar, imputar y predecir.\n",
    "\n",
    "dia_actual = 8\n",
    "dia_siguiente = 9\n",
    "\n",
    "df_predicciones_09_11, df_inicio_actualizado, mse_09_11, r2_09_11, mae_09_11 = predecir_y_actualizar_para_un_dia(dia_actual, dia_siguiente, 11, 2023, df_inicio_actualizado, df_final, model, mice_imputer)\n",
    "print(\"MSE:\", mse_09_11, \"R²:\", r2_09_11, \"MAE:\", mae_09_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma real:  102.43700000000001\n",
      "Suma predicha:  104.05211687088013\n",
      "Desviación porcentual:  1.5766928657419828 %\n",
      "Suma previsión:  127.30000000000001\n",
      "Desviación porcentual:  24.271503460663627 %\n"
     ]
    }
   ],
   "source": [
    "# Sumatorios y procentajes\n",
    "\n",
    "suma_real_09_11 = df_predicciones_09_11['E_SIMEL'].sum()\n",
    "suma_predicha_09_11 = df_predicciones_09_11['Prediccion_E_SIMEL'].sum()\n",
    "suma_prevision_09_11 = df_predicciones_09_11['PREVISION'].sum()\n",
    "\n",
    "\n",
    "if suma_real_09_11 != 0:\n",
    "    desviacion_porcentual = 100 * (suma_predicha_09_11 - suma_real_09_11) / suma_real_09_11\n",
    "else:\n",
    "    desviacion_porcentual = float('inf')  \n",
    "\n",
    "\n",
    "\n",
    "if suma_real_09_11 != 0:\n",
    "    desviacion_porcentual_prevision = 100 * (suma_prevision_09_11 - suma_real_09_11) / suma_real_09_11\n",
    "else:\n",
    "    desviacion_porcentual_prevision = float('inf')  \n",
    "    \n",
    "\n",
    "print(\"Suma real: \", suma_real_09_11)\n",
    "print(\"Suma predicha: \", suma_predicha_09_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual, \"%\")\n",
    "print(\"Suma previsión: \", suma_prevision_09_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual_prevision, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 36.2771 - mae: 3.1823 - val_loss: 50.8057 - val_mae: 3.7420 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 37.5122 - mae: 3.2454 - val_loss: 55.7127 - val_mae: 3.9159 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.9573 - mae: 3.2174 - val_loss: 58.8828 - val_mae: 4.1932 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.9703 - mae: 3.2190 - val_loss: 55.6861 - val_mae: 3.9032 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.8112 - mae: 3.2120 - val_loss: 54.9308 - val_mae: 3.9161 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.8433 - mae: 3.2471 - val_loss: 56.0519 - val_mae: 4.0305 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.9512 - mae: 3.2344 - val_loss: 58.1487 - val_mae: 4.1565 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 37.4250 - mae: 3.2622 - val_loss: 61.5258 - val_mae: 4.3448 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.6187 - mae: 3.2191 - val_loss: 50.2314 - val_mae: 3.7489 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.2504 - mae: 3.2105 - val_loss: 75.2412 - val_mae: 4.6696 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.7967 - mae: 3.2290 - val_loss: 78.0094 - val_mae: 4.8372 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.3068 - mae: 3.2104 - val_loss: 68.5048 - val_mae: 4.5975 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 35.8030 - mae: 3.2044 - val_loss: 62.0555 - val_mae: 4.2424 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.4322 - mae: 3.2085 - val_loss: 67.0809 - val_mae: 4.4969 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 36.4391 - mae: 3.2273 - val_loss: 87.9489 - val_mae: 5.0441 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 37.0224 - mae: 3.2462 - val_loss: 68.6440 - val_mae: 4.4582 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 36.4302 - mae: 3.2276 - val_loss: 76.0096 - val_mae: 4.5930 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 36.2538 - mae: 3.2093 - val_loss: 87.8044 - val_mae: 5.0529 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 35.2981 - mae: 3.1709 - val_loss: 95.5821 - val_mae: 5.2380 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 35.8211 - mae: 3.2016 - val_loss: 79.6997 - val_mae: 4.7797 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 36.6093 - mae: 3.2387 - val_loss: 86.9321 - val_mae: 5.0486 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 36.2354 - mae: 3.2181 - val_loss: 99.3740 - val_mae: 5.4177 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 35.8445 - mae: 3.2225 - val_loss: 90.2663 - val_mae: 5.1432 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 36.3946 - mae: 3.2264 - val_loss: 81.6299 - val_mae: 4.9492 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 36.2235 - mae: 3.2124 - val_loss: 69.3566 - val_mae: 4.5190 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 36.4073 - mae: 3.2235 - val_loss: 73.6659 - val_mae: 4.6830 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 35.5511 - mae: 3.1973 - val_loss: 73.9171 - val_mae: 4.7129 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 36.1940 - mae: 3.2191 - val_loss: 70.5186 - val_mae: 4.4907 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 35.5225 - mae: 3.2034 - val_loss: 71.6973 - val_mae: 4.6101 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 36.2418 - mae: 3.2205 - val_loss: 73.2838 - val_mae: 4.7360 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "621/621 [==============================] - 1s 1ms/step - loss: 35.4478 - mae: 3.1889 - val_loss: 74.7130 - val_mae: 4.5560 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 35.9429 - mae: 3.2250 - val_loss: 77.3900 - val_mae: 4.7556 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 35.5864 - mae: 3.2326 - val_loss: 58.1275 - val_mae: 4.0205 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "611/621 [============================>.] - ETA: 0s - loss: 35.9891 - mae: 3.2214Restoring model weights from the end of the best epoch: 9.\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 35.9134 - mae: 3.2225 - val_loss: 65.4869 - val_mae: 4.4161 - lr: 0.0010\n",
      "Epoch 34: early stopping\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "MSE: 35.95821100738192 R²: -0.48355065964195365 MAE: 3.0883661476771036\n"
     ]
    }
   ],
   "source": [
    "# Llamamos a la función\n",
    "dia_actual = 9\n",
    "dia_siguiente = 10\n",
    "\n",
    "df_predicciones_10_11, df_inicio_actualizado, mse_10_11, r2_10_11, mae_10_11 = predecir_y_actualizar_para_un_dia(dia_actual,dia_siguiente, 11, 2023, df_inicio_actualizado, df_final, model, mice_imputer)\n",
    "print(\"MSE:\", mse_10_11, \"R²:\", r2_10_11, \"MAE:\", mae_10_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma real:  58.955\n",
      "Suma predicha:  133.0757875442505\n",
      "Desviación porcentual:  125.72434491434228 %\n",
      "Suma previsión:  112.6\n",
      "Desviación porcentual:  90.99313035365958 %\n"
     ]
    }
   ],
   "source": [
    "# Sumatorios y porcentajes\n",
    "\n",
    "suma_real_10_11 = df_predicciones_10_11['E_SIMEL'].sum()\n",
    "suma_predicha_10_11 = df_predicciones_10_11['Prediccion_E_SIMEL'].sum()\n",
    "suma_prevision_10_11 = df_predicciones_10_11['PREVISION'].sum()\n",
    "\n",
    "\n",
    "if suma_real_10_11 != 0:\n",
    "    desviacion_porcentual = 100 * (suma_predicha_10_11 - suma_real_10_11) / suma_real_10_11\n",
    "else:\n",
    "    desviacion_porcentual = float('inf')  \n",
    "\n",
    "\n",
    "\n",
    "if suma_real_10_11 != 0:\n",
    "    desviacion_porcentual_prevision = 100 * (suma_prevision_10_11 - suma_real_10_11) / suma_real_10_11\n",
    "else:\n",
    "    desviacion_porcentual_prevision = float('inf')  \n",
    "\n",
    "print(\"Suma real: \", suma_real_10_11)\n",
    "print(\"Suma predicha: \", suma_predicha_10_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual, \"%\")\n",
    "print(\"Suma previsión: \", suma_prevision_10_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual_prevision, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 37.1600 - mae: 3.2335 - val_loss: 54.4703 - val_mae: 3.8692 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 36.1284 - mae: 3.2012 - val_loss: 52.0060 - val_mae: 3.7854 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.4517 - mae: 3.2284 - val_loss: 71.9993 - val_mae: 4.5333 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.2203 - mae: 3.2174 - val_loss: 72.1539 - val_mae: 4.5940 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.3564 - mae: 3.2303 - val_loss: 65.0311 - val_mae: 4.3789 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.3498 - mae: 3.2087 - val_loss: 63.9549 - val_mae: 4.3214 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.1364 - mae: 3.2101 - val_loss: 67.2193 - val_mae: 4.5450 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.8155 - mae: 3.2537 - val_loss: 66.0123 - val_mae: 4.3521 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 36.4769 - mae: 3.2187 - val_loss: 58.9451 - val_mae: 4.1207 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.3206 - mae: 3.2466 - val_loss: 66.0418 - val_mae: 4.2883 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 37.0061 - mae: 3.2509 - val_loss: 72.5414 - val_mae: 4.7069 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.3252 - mae: 3.2461 - val_loss: 65.6466 - val_mae: 4.2975 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 35.7826 - mae: 3.1995 - val_loss: 58.8503 - val_mae: 4.0191 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.5513 - mae: 3.2553 - val_loss: 70.5329 - val_mae: 4.5065 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.0065 - mae: 3.2223 - val_loss: 64.4058 - val_mae: 4.3224 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.2952 - mae: 3.2251 - val_loss: 55.7830 - val_mae: 3.9539 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.0434 - mae: 3.2256 - val_loss: 55.2009 - val_mae: 3.9579 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.0156 - mae: 3.2166 - val_loss: 69.4008 - val_mae: 4.4292 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.1677 - mae: 3.2201 - val_loss: 61.3318 - val_mae: 4.2465 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.1188 - mae: 3.2182 - val_loss: 59.4056 - val_mae: 4.0778 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 35.5739 - mae: 3.2065 - val_loss: 69.9661 - val_mae: 4.6704 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 35.5013 - mae: 3.2114 - val_loss: 70.2830 - val_mae: 4.5520 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 35.7766 - mae: 3.2159 - val_loss: 66.6966 - val_mae: 4.3731 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 35.6167 - mae: 3.2123 - val_loss: 62.8333 - val_mae: 4.3130 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.9996 - mae: 3.2438 - val_loss: 62.1632 - val_mae: 4.2395 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.4365 - mae: 3.1955 - val_loss: 71.1977 - val_mae: 4.6368 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "590/622 [===========================>..] - ETA: 0s - loss: 35.7828 - mae: 3.2328Restoring model weights from the end of the best epoch: 2.\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 35.7827 - mae: 3.2350 - val_loss: 65.3468 - val_mae: 4.3909 - lr: 0.0010\n",
      "Epoch 27: early stopping\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "MSE: 50.915913028595924 R²: 0.4164114074891889 MAE: 3.316407791932424\n"
     ]
    }
   ],
   "source": [
    "# Llamamos a la función\n",
    "\n",
    "dia_actual = 10\n",
    "dia_siguiente = 13\n",
    "\n",
    "df_predicciones_13_11, df_inicio_actualizado, mse_13_11, r2_13_11, mae_13_11 = predecir_y_actualizar_para_un_dia(dia_actual,dia_siguiente, 11, 2023, df_inicio_actualizado, df_final, model, mice_imputer)\n",
    "print(\"MSE:\", mse_13_11, \"R²:\", r2_13_11, \"MAE:\", mae_13_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma real:  107.141\n",
      "Suma predicha:  44.470181941986084\n",
      "Desviación porcentual:  -58.49377741295481 %\n",
      "Suma previsión:  20.900000000000002\n",
      "Desviación porcentual:  -80.492995211917 %\n"
     ]
    }
   ],
   "source": [
    "# Sumas y porcentajes\n",
    "\n",
    "suma_real_13_11 = df_predicciones_13_11['E_SIMEL'].sum()\n",
    "suma_predicha_13_11 = df_predicciones_13_11['Prediccion_E_SIMEL'].sum()\n",
    "suma_prevision_13_11 = df_predicciones_13_11['PREVISION'].sum()\n",
    "\n",
    "if suma_real_13_11 != 0:\n",
    "    desviacion_porcentual = 100 * (suma_predicha_13_11 - suma_real_13_11) / suma_real_13_11\n",
    "else:\n",
    "    desviacion_porcentual = float('inf')  \n",
    "\n",
    "\n",
    "\n",
    "if suma_real_13_11 != 0:\n",
    "    desviacion_porcentual_prevision = 100 * (suma_prevision_13_11 - suma_real_13_11) / suma_real_13_11\n",
    "else:\n",
    "    desviacion_porcentual_prevision = float('inf')  \n",
    "\n",
    "print(\"Suma real: \", suma_real_13_11)\n",
    "print(\"Suma predicha: \", suma_predicha_13_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual, \"%\")\n",
    "print(\"Suma previsión: \", suma_prevision_13_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual_prevision, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 36.8643 - mae: 3.2293 - val_loss: 57.9758 - val_mae: 4.0666 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.4722 - mae: 3.2059 - val_loss: 73.0620 - val_mae: 4.6849 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.4243 - mae: 3.2086 - val_loss: 64.1403 - val_mae: 4.1956 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.2233 - mae: 3.2114 - val_loss: 58.3026 - val_mae: 4.0104 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 35.7910 - mae: 3.1804 - val_loss: 75.0239 - val_mae: 4.5983 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.1827 - mae: 3.2289 - val_loss: 61.2207 - val_mae: 4.1000 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.6655 - mae: 3.1990 - val_loss: 78.5891 - val_mae: 4.6856 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.5278 - mae: 3.1810 - val_loss: 70.5011 - val_mae: 4.4996 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 36.5594 - mae: 3.2289 - val_loss: 72.2542 - val_mae: 4.6596 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.8811 - mae: 3.2033 - val_loss: 67.2844 - val_mae: 4.5387 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 36.4954 - mae: 3.2252 - val_loss: 61.3358 - val_mae: 4.2358 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.8261 - mae: 3.2040 - val_loss: 67.1324 - val_mae: 4.5075 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.8713 - mae: 3.2198 - val_loss: 71.9837 - val_mae: 4.4880 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.4725 - mae: 3.1905 - val_loss: 65.0406 - val_mae: 4.3239 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 36.1679 - mae: 3.2506 - val_loss: 64.9943 - val_mae: 4.2846 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 36.4906 - mae: 3.2468 - val_loss: 62.1571 - val_mae: 4.3207 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.6447 - mae: 3.1933 - val_loss: 70.0792 - val_mae: 4.5421 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 36.1034 - mae: 3.2375 - val_loss: 65.4662 - val_mae: 4.2543 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 35.8316 - mae: 3.2094 - val_loss: 70.5206 - val_mae: 4.5589 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.6017 - mae: 3.2197 - val_loss: 66.6629 - val_mae: 4.3424 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.9716 - mae: 3.2106 - val_loss: 67.1086 - val_mae: 4.2776 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.7700 - mae: 3.2047 - val_loss: 67.6024 - val_mae: 4.3848 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.5819 - mae: 3.2097 - val_loss: 62.7458 - val_mae: 4.0680 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "622/622 [==============================] - 1s 1ms/step - loss: 36.0392 - mae: 3.2458 - val_loss: 65.6674 - val_mae: 4.2578 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 36.2378 - mae: 3.2372 - val_loss: 68.6826 - val_mae: 4.4163 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "606/622 [============================>.] - ETA: 0s - loss: 34.9791 - mae: 3.2005Restoring model weights from the end of the best epoch: 1.\n",
      "622/622 [==============================] - 1s 2ms/step - loss: 35.2521 - mae: 3.2097 - val_loss: 66.9196 - val_mae: 4.5086 - lr: 0.0010\n",
      "Epoch 26: early stopping\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "MSE: 43.635878265302786 R²: 0.5365167471500769 MAE: 3.2823240315119424\n"
     ]
    }
   ],
   "source": [
    "# Llamamos a la función\n",
    "\n",
    "dia_actual = 13\n",
    "dia_siguiente = 14\n",
    "\n",
    "df_predicciones_14_11, df_inicio_actualizado, mse_14_11, r2_14_11, mae_14_11 = predecir_y_actualizar_para_un_dia(dia_actual,dia_siguiente, 11, 2023, df_inicio_actualizado, df_final, model, mice_imputer)\n",
    "print(\"MSE:\", mse_14_11, \"R²:\", r2_14_11, \"MAE:\", mae_14_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma real:  112.33099999999999\n",
      "Suma predicha:  75.91315746307373\n",
      "Desviación porcentual:  -32.42011780979984 %\n",
      "Suma previsión:  120.5\n",
      "Desviación porcentual:  7.272257880727503 %\n"
     ]
    }
   ],
   "source": [
    "# Sumatorios y porcentajes\n",
    "\n",
    "suma_real_14_11 = df_predicciones_14_11['E_SIMEL'].sum()\n",
    "suma_predicha_14_11 = df_predicciones_14_11['Prediccion_E_SIMEL'].sum()\n",
    "suma_prevision_14_11 = df_predicciones_14_11['PREVISION'].sum()\n",
    "\n",
    "if suma_real_14_11 != 0:\n",
    "    desviacion_porcentual = 100 * (suma_predicha_14_11 - suma_real_14_11) / suma_real_14_11\n",
    "else:\n",
    "    desviacion_porcentual = float('inf')  \n",
    "\n",
    "\n",
    "\n",
    "if suma_real_14_11 != 0:\n",
    "    desviacion_porcentual_prevision = 100 * (suma_prevision_14_11 - suma_real_14_11) / suma_real_14_11\n",
    "else:\n",
    "    desviacion_porcentual_prevision = float('inf')  \n",
    "\n",
    "print(\"Suma real: \", suma_real_14_11)\n",
    "print(\"Suma predicha: \", suma_predicha_14_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual, \"%\")\n",
    "print(\"Suma previsión: \", suma_prevision_14_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual_prevision, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 36.6687 - mae: 3.2179 - val_loss: 55.5017 - val_mae: 4.0614 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 37.5682 - mae: 3.2392 - val_loss: 67.4780 - val_mae: 4.4758 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 36.2791 - mae: 3.2195 - val_loss: 71.8713 - val_mae: 4.5576 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 36.0242 - mae: 3.2108 - val_loss: 66.7812 - val_mae: 4.3626 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 36.3500 - mae: 3.2168 - val_loss: 65.6413 - val_mae: 4.3733 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 36.7552 - mae: 3.2247 - val_loss: 78.7832 - val_mae: 4.8971 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 37.1335 - mae: 3.2572 - val_loss: 62.7914 - val_mae: 4.2838 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 35.4642 - mae: 3.1830 - val_loss: 70.0589 - val_mae: 4.5695 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 36.6915 - mae: 3.2394 - val_loss: 78.6505 - val_mae: 4.7631 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 36.4699 - mae: 3.2483 - val_loss: 57.9661 - val_mae: 4.0052 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 36.6796 - mae: 3.2269 - val_loss: 67.3606 - val_mae: 4.4389 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 36.0476 - mae: 3.2515 - val_loss: 64.9969 - val_mae: 4.2566 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 36.4537 - mae: 3.2383 - val_loss: 69.7878 - val_mae: 4.6080 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 36.3288 - mae: 3.2422 - val_loss: 65.2269 - val_mae: 4.2130 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 35.8937 - mae: 3.2199 - val_loss: 67.4245 - val_mae: 4.3622 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 35.7694 - mae: 3.2213 - val_loss: 58.2061 - val_mae: 3.9580 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 36.2139 - mae: 3.2499 - val_loss: 68.6725 - val_mae: 4.4329 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 36.0238 - mae: 3.2306 - val_loss: 64.3653 - val_mae: 4.3496 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 35.2928 - mae: 3.2125 - val_loss: 78.0469 - val_mae: 4.8057 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 35.3069 - mae: 3.1941 - val_loss: 81.2519 - val_mae: 4.8512 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 36.3035 - mae: 3.2301 - val_loss: 99.0247 - val_mae: 5.4756 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 36.1226 - mae: 3.2135 - val_loss: 70.2807 - val_mae: 4.5081 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 35.7468 - mae: 3.2241 - val_loss: 73.3302 - val_mae: 4.6960 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 35.1711 - mae: 3.2096 - val_loss: 64.0942 - val_mae: 4.2024 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 35.3539 - mae: 3.2060 - val_loss: 71.9801 - val_mae: 4.5721 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "620/623 [============================>.] - ETA: 0s - loss: 35.6515 - mae: 3.2227Restoring model weights from the end of the best epoch: 1.\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 35.6990 - mae: 3.2244 - val_loss: 67.5336 - val_mae: 4.3665 - lr: 0.0010\n",
      "Epoch 26: early stopping\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "MSE: 28.088016433362085 R²: 0.4508788880437825 MAE: 3.3725026615460716\n"
     ]
    }
   ],
   "source": [
    "# Llamamos a la función\n",
    "\n",
    "dia_actual = 14\n",
    "dia_siguiente = 15\n",
    "\n",
    "df_predicciones_15_11, df_inicio_actualizado, mse_15_11, r2_15_11, mae_15_11 = predecir_y_actualizar_para_un_dia(dia_actual,dia_siguiente, 11, 2023, df_inicio_actualizado, df_final, model, mice_imputer)\n",
    "print(\"MSE:\", mse_15_11, \"R²:\", r2_15_11, \"MAE:\", mae_15_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma real:  88.333\n",
      "Suma predicha:  112.58826112747192\n",
      "Desviación porcentual:  27.45888980049577 %\n",
      "Suma previsión:  131.89999999999998\n",
      "Desviación porcentual:  49.32131819365354 %\n"
     ]
    }
   ],
   "source": [
    "# Sumas y porcentajes\n",
    "\n",
    "suma_real_15_11 = df_predicciones_15_11['E_SIMEL'].sum()\n",
    "suma_predicha_15_11 = df_predicciones_15_11['Prediccion_E_SIMEL'].sum()\n",
    "suma_prevision_15_11 = df_predicciones_15_11['PREVISION'].sum()\n",
    "\n",
    "if suma_real_15_11 != 0:\n",
    "    desviacion_porcentual = 100 * (suma_predicha_15_11 - suma_real_15_11) / suma_real_15_11\n",
    "else:\n",
    "    desviacion_porcentual = float('inf')  \n",
    "\n",
    "\n",
    "\n",
    "if suma_real_15_11 != 0:\n",
    "    desviacion_porcentual_prevision = 100 * (suma_prevision_15_11 - suma_real_15_11) / suma_real_15_11\n",
    "else:\n",
    "    desviacion_porcentual_prevision = float('inf')  \n",
    "\n",
    "print(\"Suma real: \", suma_real_15_11)\n",
    "print(\"Suma predicha: \", suma_predicha_15_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual, \"%\")\n",
    "print(\"Suma previsión: \", suma_prevision_15_11)\n",
    "print(\"Desviación porcentual: \", desviacion_porcentual_prevision, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos todos los Dataframes que contienen las prediccions, previsiones y datos reales para calcular las méstricas en conjunto\n",
    "\n",
    "df_predicciones_totales = pd.concat([df_final_05_11, df_final_06_11, df_predicciones_07_11, \n",
    "                                     df_predicciones_08_11, df_predicciones_09_11,df_predicciones_10_11, \n",
    "                                     df_predicciones_13_11, df_predicciones_14_11, df_predicciones_15_11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Predicciones:  3.021907988795528\n",
      "MSE Predicciones:  33.06885109728008\n",
      "R² Predicciones:  0.34617626181390015\n",
      "MAE Previsiones:  2.3999490740740743\n",
      "MSE Previsiones:  35.93822944907407\n",
      "R² Previsiones:  0.2894440918718205\n"
     ]
    }
   ],
   "source": [
    "# Cálculo de las métricas para ver si nos indican si mejoran los errores entren la predicción (Prediccion_E_SIMEL), previsión (PREVISION)y producción real(E_SIMEL)\n",
    "\n",
    "def calcular_metricas(df):\n",
    "    mae = mean_absolute_error(df['E_SIMEL'], df['Prediccion_E_SIMEL'])\n",
    "    mse = mean_squared_error(df['E_SIMEL'], df['Prediccion_E_SIMEL'])\n",
    "    r2 = r2_score(df['E_SIMEL'], df['Prediccion_E_SIMEL'])\n",
    "    return mae, mse, r2\n",
    "\n",
    "# Métricas para la predicciones\n",
    "\n",
    "mae_pred, mse_pred, r2_pred = calcular_metricas(df_predicciones_totales)\n",
    "\n",
    "# Cambiamos la columna de predicción por la de previsión\n",
    "\n",
    "df_previsiones = df_predicciones_totales.copy()\n",
    "df_previsiones['Prediccion_E_SIMEL'] = df_previsiones['PREVISION']\n",
    "\n",
    "# Métricas para la previsión\n",
    "\n",
    "mae_prev, mse_prev, r2_prev = calcular_metricas(df_previsiones)\n",
    "\n",
    "# Visualizamos los resultados\n",
    "\n",
    "print(\"MAE Predicciones: \", mae_pred)\n",
    "print(\"MSE Predicciones: \", mse_pred)\n",
    "print(\"R² Predicciones: \", r2_pred)\n",
    "print(\"MAE Previsiones: \", mae_prev)\n",
    "print(\"MSE Previsiones: \", mse_prev)\n",
    "print(\"R² Previsiones: \", r2_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLas métricas visualizadas nos indican que el modelo utilizado mejoran las métricas de las previsiones, vamos \\na ver a continuación si las métricas reflejan esta mejora en predicción respecto la previsión.\\n\\n'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Las métricas visualizadas nos indican que el modelo utilizado mejoran las métricas de las previsiones, vamos \n",
    "a ver a continuación si las métricas reflejan esta mejora en predicción respecto la previsión.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma de los valores en la columna E_SIMEL: 622.953\n",
      "Suma de las predicciones: 785.9031648635864\n",
      "Suma de las previsiones : 696.6\n",
      "Diferencia entre predicciones totales y E_SIMEL total: 162.95016486358645\n",
      "Diferencia entre previsiones y E_SIMEL total: 73.64700000000005\n",
      "No mejoramos la predicción respecto la PREVISION real en: 89.3031648635864, por lo tanto, con este modelo, no estamos mejorando las previsiones.\n"
     ]
    }
   ],
   "source": [
    "# Para saber si llevamos una acumulado positivo de predicciones vs previsiones sobre la producción real,\n",
    "# calculamos las diferencias absolutas\n",
    "\n",
    "# Diferencia absoluta entre la predición y la producción real\n",
    "\n",
    "df_predicciones_totales['diff_pred_real'] = abs(df_predicciones_totales['Prediccion_E_SIMEL'] - df_predicciones_totales['E_SIMEL'])\n",
    "\n",
    "# Diferencia absoluta entre la previsión y la producción real\n",
    "\n",
    "df_predicciones_totales['diff_prev_real'] = abs(df_predicciones_totales['PREVISION'] - df_predicciones_totales['E_SIMEL'])\n",
    "\n",
    "\n",
    "# sumamos todos los valores de las columnas que queremo comparar\n",
    "\n",
    "suma_e_simel = df_predicciones_totales['E_SIMEL'].sum()\n",
    "sumas_totales_predicciones = df_predicciones_totales['Prediccion_E_SIMEL'].sum()\n",
    "sumas_previsiones = df_predicciones_totales['PREVISION'].sum()\n",
    "\n",
    "\n",
    "# Calculamos las diferencias entre la prediccion y la previsión respecto la producción real E_SIMEL\n",
    "\n",
    "diferencia_prediccion_vs_produccion_real = abs(sumas_totales_predicciones - suma_e_simel)\n",
    "diferencia_prevision_vs_produccion_real = abs(sumas_previsiones - suma_e_simel)\n",
    "\n",
    "\n",
    "# Imprimimos los resultados para poder visualizar si mejoramos las previsiones a lo largo de todas las predicciones.\n",
    "\n",
    "print(f\"Suma de los valores en la columna E_SIMEL: {suma_e_simel}\")\n",
    "print(f\"Suma de las predicciones: {sumas_totales_predicciones}\")\n",
    "print(f\"Suma de las previsiones : {sumas_previsiones}\")\n",
    "\n",
    "\n",
    "print(f\"Diferencia entre predicciones totales y E_SIMEL total: {diferencia_prediccion_vs_produccion_real}\")\n",
    "print(f\"Diferencia entre previsiones y E_SIMEL total: {diferencia_prevision_vs_produccion_real}\")\n",
    "\n",
    "\n",
    "# Calculamos la diferencia entre la predicción y la previsión para saber si el modelo de predicción mejora la previsión\n",
    "\n",
    "diferencia = diferencia_prediccion_vs_produccion_real - diferencia_prevision_vs_produccion_real\n",
    "\n",
    "if diferencia_prediccion_vs_produccion_real > diferencia_prevision_vs_produccion_real:\n",
    "    print(f\"No mejoramos la predicción respecto la PREVISION real en: {diferencia}, por lo tanto, con este modelo, no estamos mejorando las previsiones.\")\n",
    "else:\n",
    "    print(f\"La predicción es MEJOR que la previsión en: {-diferencia} unidades, por lo tanto, cumplimos nuestro objetivo de mejorar la PREVISIÓN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696.5999999999999"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma_prevision = df_final['PREVISION'].sum()\n",
    "suma_prevision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622.953"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma_E_SIMEL = df_final['E_SIMEL'].sum()\n",
    "suma_E_SIMEL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
